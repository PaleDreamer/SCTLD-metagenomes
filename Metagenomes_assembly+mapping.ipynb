{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "476ce3a7",
   "metadata": {},
   "source": [
    "## *De novo* assembly \n",
    "This piece of code deals with the generation of contigs from the quality trimmed reads from the Illumina sequencer. It is a memory intensive process and will take quite some time, even with a powerful computing cluster at your fingertips. For assembly, two pieces of software are used:\n",
    "\n",
    "* MegaHIT: https://github.com/voutcn/megahit\n",
    "* QUAST: http://quast.sourceforge.net/\n",
    "\n",
    "MegaHIT has quite a few options on how to perform the assembly, so it is recommended to familiarize yourself with their options and the way the software works."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19dba421",
   "metadata": {},
   "source": [
    "#### MegaHIT\n",
    "For MegaHIT, nothing beside the quality-trimmed reads from the quality control is required. Do realise that assembly is fairly sensitive to adapters still being present, so if this step is not yet performed, then this is a must before continuing. If MegaHIT exits without providing you an exit code, try re-starting the run with the second bit of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9762085",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set parameters\n",
    "SAMPLENAME=samplename\n",
    "OUTDIR=\"$SAMPLENAME\"_assembly\n",
    "READSPATH=/path/to/reads/\n",
    "\n",
    "[ -d \"$READSPATH\" ] || { echo 'Invalid path to reads, exiting.' && exit; }\n",
    "\n",
    "#assign all reads from a single genome to a file\n",
    "MCAV=$(cat \"$OUTPUT_WORKING\"/\"$SAMPLENAME\"_names.txt)\n",
    "#this concatenates your reads into a single file\n",
    "cat \"$READSPATH\"/*_R1_001_val*.fq.gz > \"$READSPATH\"/\"$SAMPLENAME\"_reads_R1_ALL.fastq\n",
    "cat \"$READSPATH\"/*_R2_001_val*.fq.gz > \"$READSPATH\"/\"$SAMPLENAME\"_reads_R2_ALL.fastq\n",
    "\n",
    "#run megahit\n",
    "megahit --presets meta-large \\\n",
    "-1 \"$READSPATH\"/\"$SAMPLENAME\"_reads_R1_ALL.fastq \\\n",
    "-2 \"$READSPATH\"/\"$SAMPLENAME\"_reads_R2_ALL.fastq \\\n",
    "-o ../data/results/$OUTDIR --out-prefix $SAMPLENAME \\\n",
    "-t $NSLOTS \\\n",
    "-m 0.9 || { echo 'Error code 1: MegaHIT did not run, exiting.' && exit; }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "855f543a",
   "metadata": {},
   "source": [
    "Sometimes, MegaHIT will create 'bloated' assemblies from the metadata. This is often the case for complex microbiomes where some important metabolic partners are sequenced at low depth (MegaHIT needs about 9.2x coverage to accurately re-assemble the parts). There is no hard solution for this, but something that might work is normalizing the reads with BBNorm:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a32ecde",
   "metadata": {},
   "outputs": [],
   "source": [
    "#make sure Java version 7 or higher is active! Otherwise this will not work!\n",
    "bbnorm.sh in=../../01_quality/data/results/ALL_reads_R1.fq out=../../01_quality/data/results/reads_norm/ALL_normalized_R1.fq target=70 min=5\n",
    "bbnorm.sh in=../../01_quality/data/results/ALL_reads_R2.fq out=../../01_quality/data/results/reads_norm/ALL_normalized_R2.fq target=70 min=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8f90330",
   "metadata": {},
   "outputs": [],
   "source": [
    "#alternatively, this is also an option:\n",
    "bbcms.sh mincount=2 highcountfraction=0.6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41f4df2d",
   "metadata": {},
   "source": [
    "#### QUAST\n",
    "QUAST executes a quality control for your contigs. This is also a good indicator whether a set of contigs is going to be of use to you. If there are very few large contigs (>1000), binning may not work very well. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "44031458",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-1-b9de1fa3c92f>, line 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Input \u001b[0;32mIn [1]\u001b[0;36m\u001b[0m\n\u001b[0;31m    quast ../data/working/co_assembly_1/co-assembly_species.contigs.fa -o ../data/results/quast_output_co-assembly\u001b[0m\n\u001b[0m           ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "quast ../data/working/co_assembly_1/co-assembly_species.contigs.fa -o ../data/results/quast_output_co-assembly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e1c7b09",
   "metadata": {},
   "source": [
    "### Mapping\n",
    "Mapping is actually its own operation, regardless of what you do above. It is also, too little to warrant its own notebook. Mapping means re-aligning your reads back to your contigs using an aligner like Bowtie2, BWA, or something with the same funcitonalities. In this, it is important to always map the reads you used to the contigs that you generated (and later filtered). \n",
    "\n",
    "For binning, only contigs over 1000 basepairs can be considered. This is due to the fact that most binning softwares rely on the use of k-mers, and smaller sizes don't give an accurate k-mer signature for k-step =4. So, the following piece of code uses scripts from Anvi'O to do two things: fix the deflines of your contigs, so Anvi'O can use them (and makes them nice and uniform), and *remove* all contigs that are under 1000 bp. It is strongly recommended to save your contigs, so you can be sure to go back to them if you decide to go another direction with this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a6b560b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#set parameters\n",
    "SAMPLENAME=samplename\n",
    "READSPATH=/path/to/reads/\n",
    "CONTIGPATH=/path/to/contigs/\n",
    "CONTIGFILE=contigfile.fa\n",
    "\n",
    "[ -d $CONTIGPATH ] || { echo 'Invalid path to contigs, exiting.' && exit; }\n",
    "[ -d $READSPATH ] || { echo 'Invalid path to contigs, exiting.' && exit; }\n",
    "\n",
    "anvi-script-reformat-fasta $CONTIGPATH/$CONTIGFILE -o $CONTIGPATH/$SAMPLENAME.contigs-fixed.fa -l 1000 --simplify-names || { echo 'Exit code 1: unable to fix deflines, exiting.' && exit; }\n",
    "#fixes deflines for later and filters on size (set to 1000 bp)\n",
    "\n",
    "FIXEDCON=\"$SAMPLENAME\".contigs-fixed.fa\n",
    "\n",
    "bowtie2-build $CONTIGPATH/$FIXEDCON ../data/working/\"$SAMPLENAME\"_contigs || { echo 'Exit code 2: Unable to build Bowtie2-index, exiting.' && exit; }\n",
    "#this builds an index of your contigs, which only needs to happen once\n",
    "\n",
    "for f in <sample1> <sample2> <sample4> <sample5>\n",
    "do\n",
    "bowtie2 --threads $NSLOTS -x ../data/working/\"$SAMPLENAME\"_contigs -1 $READSPATH/\"$f\"_R1.fastq -2 $READSPATH/\"$f\"_R2.fastq -S ../data/working/\"$f\".sam\n",
    "#this creates an alignment of your reads to your contigs and collects that in a .sam file\n",
    "\n",
    "samtools view -F 4 -bS ../data/working/\"$f\".sam > ..data/working/\"$f\"-RAW.bam\n",
    "#this converts your sam file to a bam file, but its neither sorted nor indexed, so we use an Anvi'O script to do so:\n",
    "\n",
    "anvi-init-bam ../data/working/\"$f\"_-RAW.bam -o ../data/results/\"$f\".bam\n",
    "#as said, this is how you index and sort your bam file\n",
    "\n",
    "rm ../data/working/\"$f\"-RAW.bam\n",
    "#to prevent confusion, remove the RAW file\n",
    "\n",
    "done"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
